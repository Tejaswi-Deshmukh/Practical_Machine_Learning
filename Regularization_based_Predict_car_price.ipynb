{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhsWTRjngR7H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/car_price_prediction_regression.csv\")"
      ],
      "metadata": {
        "id": "UeC85i6Rgu9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tP70mIegyQt",
        "outputId": "634fe8cc-5bb0-4455-a6e7-b9fdb3e27843"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19237, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7-iBswxgzIh",
        "outputId": "2aa8637c-5389-4f32-e642-57964565dc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19237 entries, 0 to 19236\n",
            "Data columns (total 14 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Price             19237 non-null  int64  \n",
            " 1   Manufacturer      19237 non-null  object \n",
            " 2   Category          19237 non-null  object \n",
            " 3   Leather interior  19237 non-null  object \n",
            " 4   Fuel type         19237 non-null  object \n",
            " 5   Engine volume     19237 non-null  float64\n",
            " 6   Mileage           19237 non-null  int64  \n",
            " 7   Cylinders         19237 non-null  int64  \n",
            " 8   Gear box type     19237 non-null  object \n",
            " 9   Drive wheels      19237 non-null  object \n",
            " 10  Doors             19237 non-null  int64  \n",
            " 11  Wheel             19237 non-null  object \n",
            " 12  Color             19237 non-null  object \n",
            " 13  Airbags           19237 non-null  int64  \n",
            "dtypes: float64(1), int64(5), object(8)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ohe = pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "OKHs_tE_g2xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ohe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB0no1Vrg8fd",
        "outputId": "81385be5-795f-4062-96f9-dccf0dd9f414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19237, 116)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ohe['Price'].skew()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPHThMBhg914",
        "outputId": "1e14cd5e-4616-47c7-c140-487b36d8a54d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(136.47042654268714)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ohe['Price'].hist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "_sy0aNvx854p",
        "outputId": "2296883e-bc4c-4415-c2f8-ea04d8cef162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X & Y split"
      ],
      "metadata": {
        "id": "PUjtHuQ2hgpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= df_ohe.drop('Price', axis=1)\n",
        "y= df_ohe['Price']"
      ],
      "metadata": {
        "id": "mm4yXR1Shc-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zchug66hhlFm",
        "outputId": "d9974601-5d93-4706-ebe7-e949a03adc32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19237, 115), (19237,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,\n",
        "                                                 random_state=7)"
      ],
      "metadata": {
        "id": "nfw-_00PhmRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5VygV5dh4IH",
        "outputId": "f032c209-9276-445d-94e3-fab320290107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13465, 115), (5772, 115), (13465,), (5772,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create NN model for regression"
      ],
      "metadata": {
        "id": "y-OD0SBiiFAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input"
      ],
      "metadata": {
        "id": "qWyKtWIxh9Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train.shape[1]\n",
        "n_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h96MMqO7i1KN",
        "outputId": "0dacc594-02d9-4edc-84a3-af757955a32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model1 = Sequential()\n",
        "model1.add(Input((n_features,)))\n",
        "model1.add(Dense(5, activation='relu'))\n",
        "model1.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "WzIDFUaoiw3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "cTQbcf1XjHat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss=\"mse\", metrics=['mae','r2_score'])"
      ],
      "metadata": {
        "id": "eiZvVglEjJOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model (training)\n",
        "history = model1.fit( X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_split=0.3, verbose=2,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5XILLlKjZ3J",
        "outputId": "ef3e7f2a-fdc6-456b-c3ef-317c4200191a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "295/295 - 1s - 3ms/step - loss: 2396664102912.0000 - mae: 58617.3789 - r2_score: -3.1528e+01 - val_loss: 58638254080.0000 - val_mae: 21766.7207 - val_r2_score: -1.6994e+02\n",
            "Epoch 2/100\n",
            "295/295 - 1s - 4ms/step - loss: 103104593920.0000 - mae: 23924.2480 - r2_score: -3.9936e-01 - val_loss: 936340736.0000 - val_mae: 17190.1875 - val_r2_score: -1.7296e+00\n",
            "Epoch 3/100\n",
            "295/295 - 1s - 3ms/step - loss: 74202759168.0000 - mae: 20005.3457 - r2_score: -7.0953e-03 - val_loss: 627170752.0000 - val_mae: 16856.3027 - val_r2_score: -8.2830e-01\n",
            "Epoch 4/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070556672.0000 - mae: 19761.4258 - r2_score: -5.3011e-03 - val_loss: 627009472.0000 - val_mae: 16850.6113 - val_r2_score: -8.2783e-01\n",
            "Epoch 5/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070409216.0000 - mae: 19755.8066 - r2_score: -5.2991e-03 - val_loss: 626967936.0000 - val_mae: 16849.3984 - val_r2_score: -8.2771e-01\n",
            "Epoch 6/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070360064.0000 - mae: 19754.6504 - r2_score: -5.2985e-03 - val_loss: 626921472.0000 - val_mae: 16848.0527 - val_r2_score: -8.2757e-01\n",
            "Epoch 7/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070302720.0000 - mae: 19753.3438 - r2_score: -5.2977e-03 - val_loss: 626870336.0000 - val_mae: 16846.5723 - val_r2_score: -8.2743e-01\n",
            "Epoch 8/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070269952.0000 - mae: 19751.9199 - r2_score: -5.2972e-03 - val_loss: 626814272.0000 - val_mae: 16844.9668 - val_r2_score: -8.2726e-01\n",
            "Epoch 9/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070204416.0000 - mae: 19750.3711 - r2_score: -5.2963e-03 - val_loss: 626753920.0000 - val_mae: 16843.2344 - val_r2_score: -8.2709e-01\n",
            "Epoch 10/100\n",
            "295/295 - 2s - 5ms/step - loss: 74070147072.0000 - mae: 19748.7168 - r2_score: -5.2955e-03 - val_loss: 626689472.0000 - val_mae: 16841.3926 - val_r2_score: -8.2690e-01\n",
            "Epoch 11/100\n",
            "295/295 - 2s - 6ms/step - loss: 74070081536.0000 - mae: 19746.9707 - r2_score: -5.2946e-03 - val_loss: 626622848.0000 - val_mae: 16839.4648 - val_r2_score: -8.2670e-01\n",
            "Epoch 12/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069975040.0000 - mae: 19745.2910 - r2_score: -5.2931e-03 - val_loss: 626558528.0000 - val_mae: 16837.4531 - val_r2_score: -8.2652e-01\n",
            "Epoch 13/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069868544.0000 - mae: 19744.0508 - r2_score: -5.2917e-03 - val_loss: 626541632.0000 - val_mae: 16838.1094 - val_r2_score: -8.2647e-01\n",
            "Epoch 14/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069762048.0000 - mae: 19742.2285 - r2_score: -5.2904e-03 - val_loss: 626433472.0000 - val_mae: 16835.0566 - val_r2_score: -8.2615e-01\n",
            "Epoch 15/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069721088.0000 - mae: 19742.0176 - r2_score: -5.2898e-03 - val_loss: 626337088.0000 - val_mae: 16832.6074 - val_r2_score: -8.2587e-01\n",
            "Epoch 16/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069524480.0000 - mae: 19735.5312 - r2_score: -5.2871e-03 - val_loss: 626202752.0000 - val_mae: 16828.9297 - val_r2_score: -8.2548e-01\n",
            "Epoch 17/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069393408.0000 - mae: 19732.0410 - r2_score: -5.2854e-03 - val_loss: 626062720.0000 - val_mae: 16825.2402 - val_r2_score: -8.2507e-01\n",
            "Epoch 18/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069254144.0000 - mae: 19728.0840 - r2_score: -5.2834e-03 - val_loss: 625909056.0000 - val_mae: 16821.3496 - val_r2_score: -8.2462e-01\n",
            "Epoch 19/100\n",
            "295/295 - 2s - 7ms/step - loss: 74069262336.0000 - mae: 19727.8281 - r2_score: -5.2835e-03 - val_loss: 625964224.0000 - val_mae: 16825.0938 - val_r2_score: -8.2478e-01\n",
            "Epoch 20/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069090304.0000 - mae: 19726.3652 - r2_score: -5.2812e-03 - val_loss: 625647872.0000 - val_mae: 16816.3398 - val_r2_score: -8.2386e-01\n",
            "Epoch 21/100\n",
            "295/295 - 1s - 3ms/step - loss: 74068762624.0000 - mae: 19716.5508 - r2_score: -5.2767e-03 - val_loss: 625261824.0000 - val_mae: 16805.7891 - val_r2_score: -8.2274e-01\n",
            "Epoch 22/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068353024.0000 - mae: 19707.0195 - r2_score: -5.2712e-03 - val_loss: 624951040.0000 - val_mae: 16798.5938 - val_r2_score: -8.2183e-01\n",
            "Epoch 23/100\n",
            "295/295 - 1s - 2ms/step - loss: 74067927040.0000 - mae: 19696.7910 - r2_score: -5.2655e-03 - val_loss: 624406592.0000 - val_mae: 16784.8145 - val_r2_score: -8.2024e-01\n",
            "Epoch 24/100\n",
            "295/295 - 1s - 3ms/step - loss: 74066960384.0000 - mae: 19671.4043 - r2_score: -5.2522e-03 - val_loss: 623134144.0000 - val_mae: 16747.4648 - val_r2_score: -8.1653e-01\n",
            "Epoch 25/100\n",
            "295/295 - 1s - 4ms/step - loss: 74066796544.0000 - mae: 19667.7266 - r2_score: -5.2501e-03 - val_loss: 624780032.0000 - val_mae: 16796.0039 - val_r2_score: -8.2133e-01\n",
            "Epoch 26/100\n",
            "295/295 - 1s - 3ms/step - loss: 74067763200.0000 - mae: 19693.3066 - r2_score: -5.2632e-03 - val_loss: 624261632.0000 - val_mae: 16780.9668 - val_r2_score: -8.1982e-01\n",
            "Epoch 27/100\n",
            "295/295 - 1s - 3ms/step - loss: 74067353600.0000 - mae: 19684.0762 - r2_score: -5.2576e-03 - val_loss: 623991488.0000 - val_mae: 16775.5078 - val_r2_score: -8.1903e-01\n",
            "Epoch 28/100\n",
            "295/295 - 1s - 4ms/step - loss: 74066771968.0000 - mae: 19669.3301 - r2_score: -5.2497e-03 - val_loss: 623125440.0000 - val_mae: 16752.4453 - val_r2_score: -8.1651e-01\n",
            "Epoch 29/100\n",
            "295/295 - 2s - 5ms/step - loss: 74066010112.0000 - mae: 19651.1992 - r2_score: -5.2395e-03 - val_loss: 621419136.0000 - val_mae: 16703.6133 - val_r2_score: -8.1153e-01\n",
            "Epoch 30/100\n",
            "295/295 - 1s - 5ms/step - loss: 74074349568.0000 - mae: 19695.4922 - r2_score: -5.3526e-03 - val_loss: 623435456.0000 - val_mae: 16757.7461 - val_r2_score: -8.1741e-01\n",
            "Epoch 31/100\n",
            "295/295 - 1s - 3ms/step - loss: 74091118592.0000 - mae: 19729.7305 - r2_score: -5.5802e-03 - val_loss: 624799808.0000 - val_mae: 16787.2402 - val_r2_score: -8.2139e-01\n",
            "Epoch 32/100\n",
            "295/295 - 1s - 4ms/step - loss: 74067910656.0000 - mae: 19691.7461 - r2_score: -5.2651e-03 - val_loss: 624711040.0000 - val_mae: 16784.8652 - val_r2_score: -8.2113e-01\n",
            "Epoch 33/100\n",
            "295/295 - 1s - 3ms/step - loss: 74067992576.0000 - mae: 19693.7168 - r2_score: -5.2663e-03 - val_loss: 624883904.0000 - val_mae: 16791.4883 - val_r2_score: -8.2163e-01\n",
            "Epoch 34/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070769664.0000 - mae: 19714.0566 - r2_score: -5.3040e-03 - val_loss: 626566336.0000 - val_mae: 16839.9355 - val_r2_score: -8.2654e-01\n",
            "Epoch 35/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069868544.0000 - mae: 19745.0273 - r2_score: -5.2918e-03 - val_loss: 626538880.0000 - val_mae: 16839.3047 - val_r2_score: -8.2646e-01\n",
            "Epoch 36/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069835776.0000 - mae: 19744.3105 - r2_score: -5.2913e-03 - val_loss: 626504320.0000 - val_mae: 16838.5391 - val_r2_score: -8.2636e-01\n",
            "Epoch 37/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069786624.0000 - mae: 19743.4609 - r2_score: -5.2906e-03 - val_loss: 626460736.0000 - val_mae: 16837.5684 - val_r2_score: -8.2623e-01\n",
            "Epoch 38/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069745664.0000 - mae: 19742.3789 - r2_score: -5.2900e-03 - val_loss: 626405248.0000 - val_mae: 16836.3477 - val_r2_score: -8.2607e-01\n",
            "Epoch 39/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069655552.0000 - mae: 19740.9883 - r2_score: -5.2890e-03 - val_loss: 626330560.0000 - val_mae: 16834.6836 - val_r2_score: -8.2585e-01\n",
            "Epoch 40/100\n",
            "295/295 - 2s - 5ms/step - loss: 74069540864.0000 - mae: 19738.9902 - r2_score: -5.2874e-03 - val_loss: 626223296.0000 - val_mae: 16832.2168 - val_r2_score: -8.2554e-01\n",
            "Epoch 41/100\n",
            "295/295 - 2s - 5ms/step - loss: 74069434368.0000 - mae: 19735.9219 - r2_score: -5.2859e-03 - val_loss: 626054848.0000 - val_mae: 16828.1211 - val_r2_score: -8.2505e-01\n",
            "Epoch 42/100\n",
            "295/295 - 2s - 6ms/step - loss: 74069204992.0000 - mae: 19730.0977 - r2_score: -5.2828e-03 - val_loss: 625706048.0000 - val_mae: 16819.2246 - val_r2_score: -8.2403e-01\n",
            "Epoch 43/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068615168.0000 - mae: 19711.7480 - r2_score: -5.2747e-03 - val_loss: 624446208.0000 - val_mae: 16781.7891 - val_r2_score: -8.2036e-01\n",
            "Epoch 44/100\n",
            "295/295 - 1s - 4ms/step - loss: 74073817088.0000 - mae: 19721.4512 - r2_score: -5.3453e-03 - val_loss: 626798592.0000 - val_mae: 16843.1211 - val_r2_score: -8.2722e-01\n",
            "Epoch 45/100\n",
            "295/295 - 1s - 5ms/step - loss: 74070122496.0000 - mae: 19748.7031 - r2_score: -5.2952e-03 - val_loss: 626789504.0000 - val_mae: 16842.8652 - val_r2_score: -8.2719e-01\n",
            "Epoch 46/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070106112.0000 - mae: 19748.4453 - r2_score: -5.2950e-03 - val_loss: 626780224.0000 - val_mae: 16842.5918 - val_r2_score: -8.2716e-01\n",
            "Epoch 47/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070097920.0000 - mae: 19748.1855 - r2_score: -5.2949e-03 - val_loss: 626770624.0000 - val_mae: 16842.3105 - val_r2_score: -8.2713e-01\n",
            "Epoch 48/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070097920.0000 - mae: 19747.9102 - r2_score: -5.2949e-03 - val_loss: 626760384.0000 - val_mae: 16842.0176 - val_r2_score: -8.2710e-01\n",
            "Epoch 49/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070073344.0000 - mae: 19747.6211 - r2_score: -5.2946e-03 - val_loss: 626749952.0000 - val_mae: 16841.7188 - val_r2_score: -8.2707e-01\n",
            "Epoch 50/100\n",
            "295/295 - 1s - 5ms/step - loss: 74070073344.0000 - mae: 19747.3359 - r2_score: -5.2946e-03 - val_loss: 626738880.0000 - val_mae: 16841.4082 - val_r2_score: -8.2704e-01\n",
            "Epoch 51/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070040576.0000 - mae: 19747.0176 - r2_score: -5.2941e-03 - val_loss: 626727232.0000 - val_mae: 16841.0840 - val_r2_score: -8.2701e-01\n",
            "Epoch 52/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070032384.0000 - mae: 19746.7070 - r2_score: -5.2941e-03 - val_loss: 626715456.0000 - val_mae: 16840.7578 - val_r2_score: -8.2697e-01\n",
            "Epoch 53/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070007808.0000 - mae: 19746.3652 - r2_score: -5.2936e-03 - val_loss: 626702976.0000 - val_mae: 16840.4141 - val_r2_score: -8.2694e-01\n",
            "Epoch 54/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069991424.0000 - mae: 19746.0273 - r2_score: -5.2935e-03 - val_loss: 626690048.0000 - val_mae: 16840.0547 - val_r2_score: -8.2690e-01\n",
            "Epoch 55/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069983232.0000 - mae: 19745.6797 - r2_score: -5.2934e-03 - val_loss: 626676160.0000 - val_mae: 16839.6797 - val_r2_score: -8.2686e-01\n",
            "Epoch 56/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069950464.0000 - mae: 19745.3027 - r2_score: -5.2929e-03 - val_loss: 626662208.0000 - val_mae: 16839.2910 - val_r2_score: -8.2682e-01\n",
            "Epoch 57/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069934080.0000 - mae: 19744.9238 - r2_score: -5.2927e-03 - val_loss: 626647488.0000 - val_mae: 16838.8926 - val_r2_score: -8.2678e-01\n",
            "Epoch 58/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069917696.0000 - mae: 19744.5254 - r2_score: -5.2924e-03 - val_loss: 626632448.0000 - val_mae: 16838.4746 - val_r2_score: -8.2673e-01\n",
            "Epoch 59/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069909504.0000 - mae: 19744.1094 - r2_score: -5.2923e-03 - val_loss: 626616512.0000 - val_mae: 16838.0527 - val_r2_score: -8.2669e-01\n",
            "Epoch 60/100\n",
            "295/295 - 2s - 6ms/step - loss: 74069868544.0000 - mae: 19743.6855 - r2_score: -5.2918e-03 - val_loss: 626599744.0000 - val_mae: 16837.6191 - val_r2_score: -8.2664e-01\n",
            "Epoch 61/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069860352.0000 - mae: 19743.2402 - r2_score: -5.2916e-03 - val_loss: 626582336.0000 - val_mae: 16837.1641 - val_r2_score: -8.2659e-01\n",
            "Epoch 62/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069827584.0000 - mae: 19742.7832 - r2_score: -5.2912e-03 - val_loss: 626564480.0000 - val_mae: 16836.7070 - val_r2_score: -8.2653e-01\n",
            "Epoch 63/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069819392.0000 - mae: 19742.3340 - r2_score: -5.2910e-03 - val_loss: 626546368.0000 - val_mae: 16836.2285 - val_r2_score: -8.2648e-01\n",
            "Epoch 64/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069786624.0000 - mae: 19741.8535 - r2_score: -5.2906e-03 - val_loss: 626526976.0000 - val_mae: 16835.7363 - val_r2_score: -8.2642e-01\n",
            "Epoch 65/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069762048.0000 - mae: 19741.3555 - r2_score: -5.2904e-03 - val_loss: 626506432.0000 - val_mae: 16835.2305 - val_r2_score: -8.2636e-01\n",
            "Epoch 66/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069753856.0000 - mae: 19740.8242 - r2_score: -5.2902e-03 - val_loss: 626485440.0000 - val_mae: 16834.7090 - val_r2_score: -8.2630e-01\n",
            "Epoch 67/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069721088.0000 - mae: 19740.2715 - r2_score: -5.2898e-03 - val_loss: 626462976.0000 - val_mae: 16834.1562 - val_r2_score: -8.2624e-01\n",
            "Epoch 68/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069696512.0000 - mae: 19739.7090 - r2_score: -5.2894e-03 - val_loss: 626438400.0000 - val_mae: 16833.5703 - val_r2_score: -8.2617e-01\n",
            "Epoch 69/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069663744.0000 - mae: 19739.0762 - r2_score: -5.2890e-03 - val_loss: 626411264.0000 - val_mae: 16832.9395 - val_r2_score: -8.2609e-01\n",
            "Epoch 70/100\n",
            "295/295 - 2s - 5ms/step - loss: 74069647360.0000 - mae: 19738.3945 - r2_score: -5.2887e-03 - val_loss: 626381440.0000 - val_mae: 16832.2715 - val_r2_score: -8.2600e-01\n",
            "Epoch 71/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069606400.0000 - mae: 19737.6523 - r2_score: -5.2882e-03 - val_loss: 626347392.0000 - val_mae: 16831.5352 - val_r2_score: -8.2590e-01\n",
            "Epoch 72/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069598208.0000 - mae: 19736.8184 - r2_score: -5.2880e-03 - val_loss: 626306624.0000 - val_mae: 16830.7070 - val_r2_score: -8.2578e-01\n",
            "Epoch 73/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069557248.0000 - mae: 19735.8281 - r2_score: -5.2875e-03 - val_loss: 626254592.0000 - val_mae: 16829.6699 - val_r2_score: -8.2563e-01\n",
            "Epoch 74/100\n",
            "295/295 - 1s - 5ms/step - loss: 74069491712.0000 - mae: 19734.5020 - r2_score: -5.2866e-03 - val_loss: 626173696.0000 - val_mae: 16828.2656 - val_r2_score: -8.2539e-01\n",
            "Epoch 75/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069385216.0000 - mae: 19732.4062 - r2_score: -5.2853e-03 - val_loss: 626028928.0000 - val_mae: 16825.8535 - val_r2_score: -8.2497e-01\n",
            "Epoch 76/100\n",
            "295/295 - 1s - 5ms/step - loss: 75089838080.0000 - mae: 20047.8379 - r2_score: -1.9135e-02 - val_loss: 626127872.0000 - val_mae: 16826.9355 - val_r2_score: -8.2526e-01\n",
            "Epoch 77/100\n",
            "295/295 - 1s - 4ms/step - loss: 75133444096.0000 - mae: 20045.4395 - r2_score: -1.9727e-02 - val_loss: 626369856.0000 - val_mae: 16830.6562 - val_r2_score: -8.2597e-01\n",
            "Epoch 78/100\n",
            "295/295 - 1s - 5ms/step - loss: 74069630976.0000 - mae: 19736.8047 - r2_score: -5.2885e-03 - val_loss: 626373376.0000 - val_mae: 16830.5723 - val_r2_score: -8.2598e-01\n",
            "Epoch 79/100\n",
            "295/295 - 2s - 5ms/step - loss: 74069622784.0000 - mae: 19736.3516 - r2_score: -5.2885e-03 - val_loss: 626354240.0000 - val_mae: 16830.0898 - val_r2_score: -8.2592e-01\n",
            "Epoch 80/100\n",
            "295/295 - 1s - 5ms/step - loss: 74069614592.0000 - mae: 19735.8398 - r2_score: -5.2884e-03 - val_loss: 626332864.0000 - val_mae: 16829.5566 - val_r2_score: -8.2586e-01\n",
            "Epoch 81/100\n",
            "295/295 - 2s - 7ms/step - loss: 74069606400.0000 - mae: 19735.2812 - r2_score: -5.2882e-03 - val_loss: 626308480.0000 - val_mae: 16828.9512 - val_r2_score: -8.2579e-01\n",
            "Epoch 82/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069581824.0000 - mae: 19734.6191 - r2_score: -5.2879e-03 - val_loss: 626279552.0000 - val_mae: 16828.2539 - val_r2_score: -8.2570e-01\n",
            "Epoch 83/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069540864.0000 - mae: 19733.8652 - r2_score: -5.2874e-03 - val_loss: 626245824.0000 - val_mae: 16827.4551 - val_r2_score: -8.2560e-01\n",
            "Epoch 84/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069483520.0000 - mae: 19732.9414 - r2_score: -5.2865e-03 - val_loss: 626201792.0000 - val_mae: 16826.4375 - val_r2_score: -8.2548e-01\n",
            "Epoch 85/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069385216.0000 - mae: 19731.4922 - r2_score: -5.2853e-03 - val_loss: 626101248.0000 - val_mae: 16824.4102 - val_r2_score: -8.2518e-01\n",
            "Epoch 86/100\n",
            "295/295 - 1s - 4ms/step - loss: 1356223610880.0000 - mae: 39018.8867 - r2_score: -1.7407e+01 - val_loss: 625962816.0000 - val_mae: 16822.0781 - val_r2_score: -8.2478e-01\n",
            "Epoch 87/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069213184.0000 - mae: 19727.4961 - r2_score: -5.2829e-03 - val_loss: 625952704.0000 - val_mae: 16821.8438 - val_r2_score: -8.2475e-01\n",
            "Epoch 88/100\n",
            "295/295 - 2s - 6ms/step - loss: 74069213184.0000 - mae: 19727.2559 - r2_score: -5.2829e-03 - val_loss: 625942272.0000 - val_mae: 16821.5996 - val_r2_score: -8.2472e-01\n",
            "Epoch 89/100\n",
            "295/295 - 2s - 7ms/step - loss: 74069188608.0000 - mae: 19726.9785 - r2_score: -5.2825e-03 - val_loss: 625931264.0000 - val_mae: 16821.3457 - val_r2_score: -8.2469e-01\n",
            "Epoch 90/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069172224.0000 - mae: 19726.6953 - r2_score: -5.2824e-03 - val_loss: 625919744.0000 - val_mae: 16821.0801 - val_r2_score: -8.2465e-01\n",
            "Epoch 91/100\n",
            "295/295 - 1s - 5ms/step - loss: 74069164032.0000 - mae: 19726.4102 - r2_score: -5.2822e-03 - val_loss: 625907776.0000 - val_mae: 16820.7988 - val_r2_score: -8.2462e-01\n",
            "Epoch 92/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069155840.0000 - mae: 19726.0859 - r2_score: -5.2820e-03 - val_loss: 625895360.0000 - val_mae: 16820.5117 - val_r2_score: -8.2458e-01\n",
            "Epoch 93/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069155840.0000 - mae: 19725.7754 - r2_score: -5.2820e-03 - val_loss: 625882304.0000 - val_mae: 16820.2090 - val_r2_score: -8.2454e-01\n",
            "Epoch 94/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069131264.0000 - mae: 19725.4375 - r2_score: -5.2818e-03 - val_loss: 625869056.0000 - val_mae: 16819.8887 - val_r2_score: -8.2451e-01\n",
            "Epoch 95/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069106688.0000 - mae: 19725.1074 - r2_score: -5.2814e-03 - val_loss: 625855168.0000 - val_mae: 16819.5625 - val_r2_score: -8.2447e-01\n",
            "Epoch 96/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069098496.0000 - mae: 19724.7500 - r2_score: -5.2813e-03 - val_loss: 625840768.0000 - val_mae: 16819.2285 - val_r2_score: -8.2442e-01\n",
            "Epoch 97/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069090304.0000 - mae: 19724.3848 - r2_score: -5.2812e-03 - val_loss: 625825600.0000 - val_mae: 16818.8848 - val_r2_score: -8.2438e-01\n",
            "Epoch 98/100\n",
            "295/295 - 2s - 6ms/step - loss: 74069065728.0000 - mae: 19723.9961 - r2_score: -5.2809e-03 - val_loss: 625810112.0000 - val_mae: 16818.5312 - val_r2_score: -8.2433e-01\n",
            "Epoch 99/100\n",
            "295/295 - 2s - 7ms/step - loss: 74069057536.0000 - mae: 19723.6094 - r2_score: -5.2807e-03 - val_loss: 625793984.0000 - val_mae: 16818.1641 - val_r2_score: -8.2429e-01\n",
            "Epoch 100/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069049344.0000 - mae: 19723.2012 - r2_score: -5.2806e-03 - val_loss: 625777280.0000 - val_mae: 16817.7910 - val_r2_score: -8.2424e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test mae: %.3f' % mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHRc2k6ejfv8",
        "outputId": "a99366c8-b4ea-499d-f38c-25f79bce9a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mae: 17688.422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYf8dWqYkCZQ",
        "outputId": "23e981b0-1fcb-4d1d-dc2e-6b6d6d313555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18555.92722357956"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.min(),y.max(),y.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MobRTTekgPp",
        "outputId": "f6427ffb-eedf-4e82-8d73-bb7179bd8486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 26307500, 190581.26968400902)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "- L1\n",
        "\n",
        "feature selection\n",
        "\n",
        "\n",
        "- L2\n",
        "\n",
        "reduce coefficient values also known as weight decay\n",
        "\n",
        "- ElasticNet ( l1 & L2 )\n",
        "\n",
        "\n",
        "- Dropout Layer\n",
        "\n",
        "It controls how much of the input is passed to the next layer. This reduces overfitting.\n",
        "\n",
        "\n",
        "- Batch Normalization\n",
        "\n",
        "After calculation of the loss for complete batch, gradients are normalized for improved performance and stability in learning. It tends to make NN processing slow."
      ],
      "metadata": {
        "id": "SLm3Gs2dlut1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout layer"
      ],
      "metadata": {
        "id": "OoAqDWaenKea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Input((n_features,)))\n",
        "model1.add(Dense(5, activation='relu'))\n",
        "# model1.add(Dense(100, activation='relu'))\n",
        "# model1.add(Dense(800, activation='relu'))\n",
        "# model1.add(Dense(8, activation='relu'))\n",
        "model1.add(Dropout(0.1))\n",
        "model1.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "6UFMTCUbkoRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss=\"mse\", metrics=['mae'])"
      ],
      "metadata": {
        "id": "VNPZ44bDnPHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model (training)\n",
        "history = model1.fit( X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_split=0.3, verbose=2,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "FKVaVrhXnSA1",
        "outputId": "38b8eab9-89e8-4c9e-be7d-f6a252fec6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "295/295 - 2s - 7ms/step - loss: 21879788142592.0000 - mae: 165580.1875 - val_loss: 2278296387584.0000 - val_mae: 49099.0820\n",
            "Epoch 2/100\n",
            "295/295 - 1s - 3ms/step - loss: 14009716703232.0000 - mae: 97895.3359 - val_loss: 1712116224.0000 - val_mae: 17714.2852\n",
            "Epoch 3/100\n",
            "295/295 - 1s - 4ms/step - loss: 4706539667456.0000 - mae: 52320.1836 - val_loss: 12889422848.0000 - val_mae: 19077.2969\n",
            "Epoch 4/100\n",
            "295/295 - 1s - 3ms/step - loss: 6922194911232.0000 - mae: 71562.5703 - val_loss: 22159562752.0000 - val_mae: 20684.1875\n",
            "Epoch 5/100\n",
            "295/295 - 1s - 4ms/step - loss: 116606517248.0000 - mae: 26155.1973 - val_loss: 1067537728.0000 - val_mae: 17262.2344\n",
            "Epoch 6/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-32-3431914122.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fit the model (training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model1.fit( X_train, y_train, epochs=100, batch_size=32,\n\u001b[0m\u001b[1;32m      3\u001b[0m                      validation_split=0.3, verbose=2,shuffle=False)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test mae: %.3f' % mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ePwtbvknUkB",
        "outputId": "d244bc9e-91a6-4c60-b65b-f5c0f8729b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mae: 17724.312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization layer"
      ],
      "metadata": {
        "id": "lSMc8HlkoSNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "03nPyfiznW7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Input((n_features,)))\n",
        "model1.add(Dense(5, activation='relu'))\n",
        "# model1.add(Dense(100, activation='relu'))\n",
        "# model1.add(Dense(800, activation='relu'))\n",
        "# model1.add(Dense(8, activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "aYD6prZioXeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss=\"mse\", metrics=['mae'])"
      ],
      "metadata": {
        "id": "P3ymEzV6oclf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model (training)\n",
        "history = model1.fit( X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_split=0.3, verbose=2,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImVYxnDho5mY",
        "outputId": "8c5f3dda-d12b-4565-882e-56b534eecf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "295/295 - 2s - 8ms/step - loss: 74070745088.0000 - mae: 19768.5371 - val_loss: 627360896.0000 - val_mae: 16862.0820\n",
            "Epoch 2/100\n",
            "295/295 - 2s - 6ms/step - loss: 74070712320.0000 - mae: 19768.0781 - val_loss: 627338304.0000 - val_mae: 16861.5176\n",
            "Epoch 3/100\n",
            "295/295 - 2s - 6ms/step - loss: 74070679552.0000 - mae: 19767.4023 - val_loss: 627310400.0000 - val_mae: 16860.7520\n",
            "Epoch 4/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070679552.0000 - mae: 19766.5469 - val_loss: 627275840.0000 - val_mae: 16859.7832\n",
            "Epoch 5/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070614016.0000 - mae: 19765.4492 - val_loss: 627233152.0000 - val_mae: 16858.5859\n",
            "Epoch 6/100\n",
            "295/295 - 1s - 5ms/step - loss: 74070556672.0000 - mae: 19764.1641 - val_loss: 627184192.0000 - val_mae: 16857.2051\n",
            "Epoch 7/100\n",
            "295/295 - 2s - 6ms/step - loss: 74070523904.0000 - mae: 19762.6602 - val_loss: 627126336.0000 - val_mae: 16855.5898\n",
            "Epoch 8/100\n",
            "295/295 - 2s - 6ms/step - loss: 74070474752.0000 - mae: 19760.9531 - val_loss: 627061696.0000 - val_mae: 16853.7578\n",
            "Epoch 9/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070343680.0000 - mae: 19759.0664 - val_loss: 626991168.0000 - val_mae: 16851.7539\n",
            "Epoch 10/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070286336.0000 - mae: 19756.9980 - val_loss: 626914624.0000 - val_mae: 16849.5684\n",
            "Epoch 11/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070196224.0000 - mae: 19754.7578 - val_loss: 626835840.0000 - val_mae: 16847.3750\n",
            "Epoch 12/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070089728.0000 - mae: 19752.3887 - val_loss: 626749440.0000 - val_mae: 16844.8945\n",
            "Epoch 13/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069999616.0000 - mae: 19749.8535 - val_loss: 626660288.0000 - val_mae: 16842.3828\n",
            "Epoch 14/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069917696.0000 - mae: 19747.1934 - val_loss: 626564160.0000 - val_mae: 16839.6211\n",
            "Epoch 15/100\n",
            "295/295 - 1s - 5ms/step - loss: 74069762048.0000 - mae: 19744.3848 - val_loss: 626465152.0000 - val_mae: 16836.8516\n",
            "Epoch 16/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069598208.0000 - mae: 19741.4395 - val_loss: 626360640.0000 - val_mae: 16833.9102\n",
            "Epoch 17/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069450752.0000 - mae: 19738.3652 - val_loss: 626248000.0000 - val_mae: 16830.6836\n",
            "Epoch 18/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069327872.0000 - mae: 19735.1543 - val_loss: 626132928.0000 - val_mae: 16827.4336\n",
            "Epoch 19/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069221376.0000 - mae: 19731.8027 - val_loss: 626014976.0000 - val_mae: 16824.1562\n",
            "Epoch 20/100\n",
            "295/295 - 1s - 4ms/step - loss: 74069082112.0000 - mae: 19728.3340 - val_loss: 625884736.0000 - val_mae: 16820.5098\n",
            "Epoch 21/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068901888.0000 - mae: 19724.7363 - val_loss: 625748480.0000 - val_mae: 16817.0293\n",
            "Epoch 22/100\n",
            "295/295 - 1s - 3ms/step - loss: 74068779008.0000 - mae: 19721.0293 - val_loss: 625609280.0000 - val_mae: 16813.4844\n",
            "Epoch 23/100\n",
            "295/295 - 1s - 3ms/step - loss: 74068590592.0000 - mae: 19717.1895 - val_loss: 625467264.0000 - val_mae: 16809.5332\n",
            "Epoch 24/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068418560.0000 - mae: 19713.2246 - val_loss: 625317184.0000 - val_mae: 16805.2695\n",
            "Epoch 25/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068238336.0000 - mae: 19709.1426 - val_loss: 625171904.0000 - val_mae: 16801.3672\n",
            "Epoch 26/100\n",
            "295/295 - 1s - 4ms/step - loss: 74068058112.0000 - mae: 19704.9336 - val_loss: 625016896.0000 - val_mae: 16797.0508\n",
            "Epoch 27/100\n",
            "295/295 - 2s - 5ms/step - loss: 74067910656.0000 - mae: 19700.5918 - val_loss: 624862144.0000 - val_mae: 16792.8203\n",
            "Epoch 28/100\n",
            "295/295 - 1s - 4ms/step - loss: 74067714048.0000 - mae: 19696.1484 - val_loss: 624698752.0000 - val_mae: 16788.3027\n",
            "Epoch 29/100\n",
            "295/295 - 1s - 3ms/step - loss: 74067517440.0000 - mae: 19691.5781 - val_loss: 624524096.0000 - val_mae: 16783.3750\n",
            "Epoch 30/100\n",
            "295/295 - 1s - 3ms/step - loss: 74067304448.0000 - mae: 19686.8906 - val_loss: 624360256.0000 - val_mae: 16778.9863\n",
            "Epoch 31/100\n",
            "295/295 - 1s - 4ms/step - loss: 74067107840.0000 - mae: 19682.0781 - val_loss: 624184704.0000 - val_mae: 16774.1406\n",
            "Epoch 32/100\n",
            "295/295 - 1s - 5ms/step - loss: 74066878464.0000 - mae: 19677.1660 - val_loss: 624006464.0000 - val_mae: 16769.2988\n",
            "Epoch 33/100\n",
            "295/295 - 1s - 4ms/step - loss: 74066657280.0000 - mae: 19672.1426 - val_loss: 623810880.0000 - val_mae: 16763.7598\n",
            "Epoch 34/100\n",
            "295/295 - 1s - 3ms/step - loss: 74066452480.0000 - mae: 19667.0039 - val_loss: 623634688.0000 - val_mae: 16759.1934\n",
            "Epoch 35/100\n",
            "295/295 - 1s - 4ms/step - loss: 74066272256.0000 - mae: 19661.7383 - val_loss: 623442880.0000 - val_mae: 16753.8594\n",
            "Epoch 36/100\n",
            "295/295 - 1s - 5ms/step - loss: 74066051072.0000 - mae: 19656.3652 - val_loss: 623246976.0000 - val_mae: 16748.5293\n",
            "Epoch 37/100\n",
            "295/295 - 1s - 5ms/step - loss: 74065788928.0000 - mae: 19650.8711 - val_loss: 623036160.0000 - val_mae: 16742.6445\n",
            "Epoch 38/100\n",
            "295/295 - 1s - 4ms/step - loss: 74065534976.0000 - mae: 19645.2695 - val_loss: 622840832.0000 - val_mae: 16737.4727\n",
            "Epoch 39/100\n",
            "295/295 - 1s - 4ms/step - loss: 74065272832.0000 - mae: 19639.5449 - val_loss: 622636096.0000 - val_mae: 16731.9668\n",
            "Epoch 40/100\n",
            "295/295 - 1s - 4ms/step - loss: 74065043456.0000 - mae: 19633.7227 - val_loss: 622410816.0000 - val_mae: 16725.5703\n",
            "Epoch 41/100\n",
            "295/295 - 1s - 3ms/step - loss: 74064756736.0000 - mae: 19627.7891 - val_loss: 622189696.0000 - val_mae: 16719.6582\n",
            "Epoch 42/100\n",
            "295/295 - 1s - 3ms/step - loss: 74064510976.0000 - mae: 19621.7852 - val_loss: 621974400.0000 - val_mae: 16713.9883\n",
            "Epoch 43/100\n",
            "295/295 - 1s - 3ms/step - loss: 74064257024.0000 - mae: 19615.6562 - val_loss: 621746304.0000 - val_mae: 16707.7402\n",
            "Epoch 44/100\n",
            "295/295 - 1s - 4ms/step - loss: 74064027648.0000 - mae: 19609.4414 - val_loss: 621513472.0000 - val_mae: 16701.4219\n",
            "Epoch 45/100\n",
            "295/295 - 1s - 3ms/step - loss: 74063708160.0000 - mae: 19603.1094 - val_loss: 621274816.0000 - val_mae: 16694.9180\n",
            "Epoch 46/100\n",
            "295/295 - 1s - 4ms/step - loss: 74063388672.0000 - mae: 19596.6973 - val_loss: 621041984.0000 - val_mae: 16688.8047\n",
            "Epoch 47/100\n",
            "295/295 - 1s - 3ms/step - loss: 74063093760.0000 - mae: 19590.1836 - val_loss: 620795136.0000 - val_mae: 16682.1191\n",
            "Epoch 48/100\n",
            "295/295 - 1s - 3ms/step - loss: 74062888960.0000 - mae: 19583.5664 - val_loss: 620550080.0000 - val_mae: 16675.6445\n",
            "Epoch 49/100\n",
            "295/295 - 2s - 5ms/step - loss: 74062561280.0000 - mae: 19576.8555 - val_loss: 620297792.0000 - val_mae: 16668.9453\n",
            "Epoch 50/100\n",
            "295/295 - 1s - 4ms/step - loss: 74062249984.0000 - mae: 19570.0586 - val_loss: 620047616.0000 - val_mae: 16662.4180\n",
            "Epoch 51/100\n",
            "295/295 - 1s - 4ms/step - loss: 74061979648.0000 - mae: 19563.1426 - val_loss: 619784768.0000 - val_mae: 16655.3848\n",
            "Epoch 52/100\n",
            "295/295 - 1s - 4ms/step - loss: 74061627392.0000 - mae: 19556.1445 - val_loss: 619524032.0000 - val_mae: 16648.6484\n",
            "Epoch 53/100\n",
            "295/295 - 1s - 4ms/step - loss: 74061275136.0000 - mae: 19549.0469 - val_loss: 619251776.0000 - val_mae: 16641.3438\n",
            "Epoch 54/100\n",
            "295/295 - 1s - 4ms/step - loss: 74060972032.0000 - mae: 19541.8594 - val_loss: 618982464.0000 - val_mae: 16634.3711\n",
            "Epoch 55/100\n",
            "295/295 - 1s - 4ms/step - loss: 74060677120.0000 - mae: 19534.5859 - val_loss: 618704384.0000 - val_mae: 16626.9414\n",
            "Epoch 56/100\n",
            "295/295 - 1s - 4ms/step - loss: 74060398592.0000 - mae: 19527.1914 - val_loss: 618425664.0000 - val_mae: 16619.6719\n",
            "Epoch 57/100\n",
            "295/295 - 1s - 3ms/step - loss: 74060046336.0000 - mae: 19519.7598 - val_loss: 618144896.0000 - val_mae: 16612.3359\n",
            "Epoch 58/100\n",
            "295/295 - 1s - 3ms/step - loss: 74059661312.0000 - mae: 19512.2324 - val_loss: 617859264.0000 - val_mae: 16604.8887\n",
            "Epoch 59/100\n",
            "295/295 - 1s - 4ms/step - loss: 74059325440.0000 - mae: 19504.6172 - val_loss: 617567424.0000 - val_mae: 16597.2500\n",
            "Epoch 60/100\n",
            "295/295 - 2s - 6ms/step - loss: 74058940416.0000 - mae: 19496.8945 - val_loss: 617274240.0000 - val_mae: 16589.7422\n",
            "Epoch 61/100\n",
            "295/295 - 1s - 4ms/step - loss: 74058653696.0000 - mae: 19489.2070 - val_loss: 616976512.0000 - val_mae: 16582.1602\n",
            "Epoch 62/100\n",
            "295/295 - 1s - 3ms/step - loss: 74058334208.0000 - mae: 19481.4531 - val_loss: 616664896.0000 - val_mae: 16574.0156\n",
            "Epoch 63/100\n",
            "295/295 - 1s - 3ms/step - loss: 74057957376.0000 - mae: 19473.5508 - val_loss: 616365248.0000 - val_mae: 16566.5781\n",
            "Epoch 64/100\n",
            "295/295 - 1s - 5ms/step - loss: 74057596928.0000 - mae: 19465.6328 - val_loss: 616049664.0000 - val_mae: 16558.3984\n",
            "Epoch 65/100\n",
            "295/295 - 1s - 4ms/step - loss: 74057179136.0000 - mae: 19457.6172 - val_loss: 615738176.0000 - val_mae: 16550.5020\n",
            "Epoch 66/100\n",
            "295/295 - 1s - 4ms/step - loss: 74056810496.0000 - mae: 19449.4805 - val_loss: 615424640.0000 - val_mae: 16542.5547\n",
            "Epoch 67/100\n",
            "295/295 - 1s - 3ms/step - loss: 74056409088.0000 - mae: 19441.2656 - val_loss: 615110848.0000 - val_mae: 16534.7285\n",
            "Epoch 68/100\n",
            "295/295 - 1s - 3ms/step - loss: 74056056832.0000 - mae: 19433.0078 - val_loss: 614783296.0000 - val_mae: 16526.3262\n",
            "Epoch 69/100\n",
            "295/295 - 1s - 4ms/step - loss: 74055704576.0000 - mae: 19424.7031 - val_loss: 614456832.0000 - val_mae: 16518.3145\n",
            "Epoch 70/100\n",
            "295/295 - 1s - 4ms/step - loss: 74055294976.0000 - mae: 19416.2852 - val_loss: 614122688.0000 - val_mae: 16509.7227\n",
            "Epoch 71/100\n",
            "295/295 - 2s - 5ms/step - loss: 74054868992.0000 - mae: 19407.8594 - val_loss: 613784128.0000 - val_mae: 16501.7324\n",
            "Epoch 72/100\n",
            "295/295 - 1s - 4ms/step - loss: 74054492160.0000 - mae: 19399.3164 - val_loss: 613436672.0000 - val_mae: 16492.9551\n",
            "Epoch 73/100\n",
            "295/295 - 1s - 3ms/step - loss: 74054082560.0000 - mae: 19390.7305 - val_loss: 613092608.0000 - val_mae: 16484.5449\n",
            "Epoch 74/100\n",
            "295/295 - 1s - 4ms/step - loss: 74053672960.0000 - mae: 19382.0605 - val_loss: 612737536.0000 - val_mae: 16475.5938\n",
            "Epoch 75/100\n",
            "295/295 - 1s - 4ms/step - loss: 74053271552.0000 - mae: 19373.2949 - val_loss: 612393920.0000 - val_mae: 16467.3477\n",
            "Epoch 76/100\n",
            "295/295 - 1s - 3ms/step - loss: 74052829184.0000 - mae: 19364.5195 - val_loss: 612037056.0000 - val_mae: 16458.5801\n",
            "Epoch 77/100\n",
            "295/295 - 1s - 4ms/step - loss: 74052345856.0000 - mae: 19355.7051 - val_loss: 611695488.0000 - val_mae: 16450.6816\n",
            "Epoch 78/100\n",
            "295/295 - 1s - 4ms/step - loss: 74051960832.0000 - mae: 19346.8477 - val_loss: 611322752.0000 - val_mae: 16441.5117\n",
            "Epoch 79/100\n",
            "295/295 - 1s - 3ms/step - loss: 74051567616.0000 - mae: 19337.8652 - val_loss: 610967488.0000 - val_mae: 16433.2383\n",
            "Epoch 80/100\n",
            "295/295 - 1s - 4ms/step - loss: 74051076096.0000 - mae: 19328.8750 - val_loss: 610594240.0000 - val_mae: 16424.2129\n",
            "Epoch 81/100\n",
            "295/295 - 1s - 4ms/step - loss: 74050691072.0000 - mae: 19319.7656 - val_loss: 610216768.0000 - val_mae: 16415.0469\n",
            "Epoch 82/100\n",
            "295/295 - 2s - 6ms/step - loss: 74050191360.0000 - mae: 19310.6504 - val_loss: 609790464.0000 - val_mae: 16403.7266\n",
            "Epoch 83/100\n",
            "295/295 - 2s - 7ms/step - loss: 74049781760.0000 - mae: 19301.4746 - val_loss: 609458112.0000 - val_mae: 16397.0430\n",
            "Epoch 84/100\n",
            "295/295 - 2s - 5ms/step - loss: 74049347584.0000 - mae: 19292.2930 - val_loss: 609079936.0000 - val_mae: 16388.1289\n",
            "Epoch 85/100\n",
            "295/295 - 1s - 3ms/step - loss: 74048864256.0000 - mae: 19282.9805 - val_loss: 608682304.0000 - val_mae: 16378.2832\n",
            "Epoch 86/100\n",
            "295/295 - 1s - 4ms/step - loss: 74048356352.0000 - mae: 19273.6133 - val_loss: 608312128.0000 - val_mae: 16370.1973\n",
            "Epoch 87/100\n",
            "295/295 - 1s - 3ms/step - loss: 74047913984.0000 - mae: 19264.2402 - val_loss: 607906624.0000 - val_mae: 16360.1875\n",
            "Epoch 88/100\n",
            "295/295 - 1s - 4ms/step - loss: 74047528960.0000 - mae: 19254.7754 - val_loss: 607509696.0000 - val_mae: 16350.8799\n",
            "Epoch 89/100\n",
            "295/295 - 1s - 4ms/step - loss: 74047045632.0000 - mae: 19245.2363 - val_loss: 607106880.0000 - val_mae: 16341.4658\n",
            "Epoch 90/100\n",
            "295/295 - 1s - 3ms/step - loss: 74046464000.0000 - mae: 19235.7383 - val_loss: 606697344.0000 - val_mae: 16331.9180\n",
            "Epoch 91/100\n",
            "295/295 - 1s - 4ms/step - loss: 74045997056.0000 - mae: 19226.1211 - val_loss: 606301120.0000 - val_mae: 16322.9746\n",
            "Epoch 92/100\n",
            "295/295 - 2s - 5ms/step - loss: 74045521920.0000 - mae: 19216.4062 - val_loss: 605899840.0000 - val_mae: 16313.7812\n",
            "Epoch 93/100\n",
            "295/295 - 2s - 7ms/step - loss: 74045071360.0000 - mae: 19206.6191 - val_loss: 605482112.0000 - val_mae: 16304.0625\n",
            "Epoch 94/100\n",
            "295/295 - 1s - 4ms/step - loss: 74044563456.0000 - mae: 19196.8750 - val_loss: 605055808.0000 - val_mae: 16294.0400\n",
            "Epoch 95/100\n",
            "295/295 - 1s - 4ms/step - loss: 74044121088.0000 - mae: 19186.9785 - val_loss: 604644480.0000 - val_mae: 16284.5762\n",
            "Epoch 96/100\n",
            "295/295 - 1s - 4ms/step - loss: 74043580416.0000 - mae: 19177.2207 - val_loss: 604240704.0000 - val_mae: 16275.9053\n",
            "Epoch 97/100\n",
            "295/295 - 1s - 4ms/step - loss: 74043080704.0000 - mae: 19167.3379 - val_loss: 603802688.0000 - val_mae: 16265.7588\n",
            "Epoch 98/100\n",
            "295/295 - 1s - 4ms/step - loss: 74042548224.0000 - mae: 19157.4141 - val_loss: 603355584.0000 - val_mae: 16255.2217\n",
            "Epoch 99/100\n",
            "295/295 - 1s - 5ms/step - loss: 74042015744.0000 - mae: 19147.3281 - val_loss: 602938048.0000 - val_mae: 16246.0400\n",
            "Epoch 100/100\n",
            "295/295 - 2s - 5ms/step - loss: 74041475072.0000 - mae: 19137.3203 - val_loss: 602487168.0000 - val_mae: 16235.4873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test mae: %.3f' % mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxrAe1Wfo7_I",
        "outputId": "d4900cef-5d1a-4e4d-d275-dc8d31c90444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mae: 17119.924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L1 & L2 regularization"
      ],
      "metadata": {
        "id": "FNIOvKFTqYee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "kXa4f4uurCIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Input((n_features,)))\n",
        "model1.add(Dense(5,  kernel_regularizer=regularizers.L1L2(),\n",
        "                 activation='relu'))\n",
        "# model1.add(Dense(100, activation='relu'))\n",
        "# model1.add(Dense(800, activation='relu'))\n",
        "# model1.add(Dense(8, activation='relu'))\n",
        "model1.add(Dense(1, activation='linear'))"
      ],
      "metadata": {
        "id": "RT8kXwFWo_Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam',loss=\"mse\", metrics=['mae'])"
      ],
      "metadata": {
        "id": "ioflwzrqqxq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model (training)\n",
        "history = model1.fit( X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_split=0.3, verbose=2,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHh2dbZzrpSm",
        "outputId": "3c97477b-7046-4feb-d160-67ec76a78d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "295/295 - 2s - 6ms/step - loss: 2478312521728.0000 - mae: 58826.3555 - val_loss: 3059168000.0000 - val_mae: 17827.1055\n",
            "Epoch 2/100\n",
            "295/295 - 0s - 2ms/step - loss: 74825703424.0000 - mae: 20215.7148 - val_loss: 627578496.0000 - val_mae: 16868.0312\n",
            "Epoch 3/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070671360.0000 - mae: 19764.3164 - val_loss: 627159552.0000 - val_mae: 16855.3477\n",
            "Epoch 4/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070532096.0000 - mae: 19761.0859 - val_loss: 627099840.0000 - val_mae: 16853.6152\n",
            "Epoch 5/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070507520.0000 - mae: 19759.5098 - val_loss: 627037184.0000 - val_mae: 16851.7188\n",
            "Epoch 6/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070466560.0000 - mae: 19758.0859 - val_loss: 626980800.0000 - val_mae: 16849.8242\n",
            "Epoch 7/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070376448.0000 - mae: 19757.8359 - val_loss: 626942656.0000 - val_mae: 16849.7656\n",
            "Epoch 8/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070417408.0000 - mae: 19759.1602 - val_loss: 626940544.0000 - val_mae: 16850.1875\n",
            "Epoch 9/100\n",
            "295/295 - 1s - 4ms/step - loss: 74070614016.0000 - mae: 19764.1992 - val_loss: 627019392.0000 - val_mae: 16851.5840\n",
            "Epoch 10/100\n",
            "295/295 - 1s - 3ms/step - loss: 74071523328.0000 - mae: 19777.7129 - val_loss: 627323072.0000 - val_mae: 16855.3457\n",
            "Epoch 11/100\n",
            "295/295 - 1s - 2ms/step - loss: 74074554368.0000 - mae: 19802.7363 - val_loss: 627659264.0000 - val_mae: 16857.5898\n",
            "Epoch 12/100\n",
            "295/295 - 1s - 2ms/step - loss: 74075234304.0000 - mae: 19802.1504 - val_loss: 626436288.0000 - val_mae: 16835.5098\n",
            "Epoch 13/100\n",
            "295/295 - 0s - 2ms/step - loss: 74087071744.0000 - mae: 19828.0820 - val_loss: 626522304.0000 - val_mae: 16834.7051\n",
            "Epoch 14/100\n",
            "295/295 - 1s - 2ms/step - loss: 95233384448.0000 - mae: 22973.5508 - val_loss: 4152425984.0000 - val_mae: 17996.3281\n",
            "Epoch 15/100\n",
            "295/295 - 1s - 2ms/step - loss: 377269649408.0000 - mae: 30765.5605 - val_loss: 923800192.0000 - val_mae: 17149.9082\n",
            "Epoch 16/100\n",
            "295/295 - 1s - 3ms/step - loss: 74636992512.0000 - mae: 20241.1680 - val_loss: 632881088.0000 - val_mae: 16861.9727\n",
            "Epoch 17/100\n",
            "295/295 - 1s - 4ms/step - loss: 74092462080.0000 - mae: 19819.8926 - val_loss: 625896960.0000 - val_mae: 16818.4590\n",
            "Epoch 18/100\n",
            "295/295 - 0s - 2ms/step - loss: 74071269376.0000 - mae: 19750.8320 - val_loss: 625675520.0000 - val_mae: 16813.6445\n",
            "Epoch 19/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070630400.0000 - mae: 19736.4414 - val_loss: 625344640.0000 - val_mae: 16802.7090\n",
            "Epoch 20/100\n",
            "295/295 - 1s - 2ms/step - loss: 74330185728.0000 - mae: 20078.8125 - val_loss: 667254464.0000 - val_mae: 16918.2266\n",
            "Epoch 21/100\n",
            "295/295 - 1s - 2ms/step - loss: 248666210304.0000 - mae: 30907.8516 - val_loss: 172931268608.0000 - val_mae: 27625.5488\n",
            "Epoch 22/100\n",
            "295/295 - 0s - 2ms/step - loss: 304156770304.0000 - mae: 30350.4668 - val_loss: 645111552.0000 - val_mae: 16873.5859\n",
            "Epoch 23/100\n",
            "295/295 - 0s - 2ms/step - loss: 74090225664.0000 - mae: 19784.1504 - val_loss: 625051840.0000 - val_mae: 16795.8652\n",
            "Epoch 24/100\n",
            "295/295 - 0s - 2ms/step - loss: 74068779008.0000 - mae: 19714.3555 - val_loss: 625269056.0000 - val_mae: 16799.7051\n",
            "Epoch 25/100\n",
            "295/295 - 1s - 3ms/step - loss: 74070581248.0000 - mae: 19735.1543 - val_loss: 625706368.0000 - val_mae: 16804.2090\n",
            "Epoch 26/100\n",
            "295/295 - 1s - 4ms/step - loss: 74074341376.0000 - mae: 19758.4062 - val_loss: 625464896.0000 - val_mae: 16799.0176\n",
            "Epoch 27/100\n",
            "295/295 - 1s - 3ms/step - loss: 74069925888.0000 - mae: 19720.4629 - val_loss: 624318720.0000 - val_mae: 16773.8340\n",
            "Epoch 28/100\n",
            "295/295 - 1s - 2ms/step - loss: 74165428224.0000 - mae: 19902.6992 - val_loss: 636697024.0000 - val_mae: 16833.3145\n",
            "Epoch 29/100\n",
            "295/295 - 1s - 2ms/step - loss: 212959395840.0000 - mae: 28982.5723 - val_loss: 119318880256.0000 - val_mae: 25754.1250\n",
            "Epoch 30/100\n",
            "295/295 - 1s - 2ms/step - loss: 271416180736.0000 - mae: 29718.7656 - val_loss: 624024256.0000 - val_mae: 16765.8242\n",
            "Epoch 31/100\n",
            "295/295 - 1s - 2ms/step - loss: 74067419136.0000 - mae: 19680.1328 - val_loss: 624260352.0000 - val_mae: 16772.6191\n",
            "Epoch 32/100\n",
            "295/295 - 1s - 2ms/step - loss: 74068664320.0000 - mae: 19700.6309 - val_loss: 624608064.0000 - val_mae: 16776.8750\n",
            "Epoch 33/100\n",
            "295/295 - 0s - 2ms/step - loss: 74071965696.0000 - mae: 19725.8750 - val_loss: 624886528.0000 - val_mae: 16778.2910\n",
            "Epoch 34/100\n",
            "295/295 - 1s - 2ms/step - loss: 74072031232.0000 - mae: 19720.7480 - val_loss: 623612864.0000 - val_mae: 16755.4121\n",
            "Epoch 35/100\n",
            "295/295 - 1s - 2ms/step - loss: 74085195776.0000 - mae: 19751.5938 - val_loss: 623711040.0000 - val_mae: 16755.3477\n",
            "Epoch 36/100\n",
            "295/295 - 1s - 2ms/step - loss: 94504968192.0000 - mae: 22860.6113 - val_loss: 2760154624.0000 - val_mae: 17658.1016\n",
            "Epoch 37/100\n",
            "295/295 - 0s - 2ms/step - loss: 326194003968.0000 - mae: 29970.0039 - val_loss: 1190413568.0000 - val_mae: 17205.9551\n",
            "Epoch 38/100\n",
            "295/295 - 1s - 2ms/step - loss: 75205533696.0000 - mae: 20398.6289 - val_loss: 643138944.0000 - val_mae: 16819.4688\n",
            "Epoch 39/100\n",
            "295/295 - 1s - 2ms/step - loss: 74135166976.0000 - mae: 19827.4805 - val_loss: 624985280.0000 - val_mae: 16758.6348\n",
            "Epoch 40/100\n",
            "295/295 - 1s - 2ms/step - loss: 74076930048.0000 - mae: 19704.1816 - val_loss: 622780864.0000 - val_mae: 16730.9043\n",
            "Epoch 41/100\n",
            "295/295 - 1s - 2ms/step - loss: 74068590592.0000 - mae: 19663.5879 - val_loss: 622614528.0000 - val_mae: 16726.2910\n",
            "Epoch 42/100\n",
            "295/295 - 1s - 2ms/step - loss: 74538803200.0000 - mae: 20131.1230 - val_loss: 709461184.0000 - val_mae: 16898.7070\n",
            "Epoch 43/100\n",
            "295/295 - 1s - 3ms/step - loss: 199560314880.0000 - mae: 29658.5469 - val_loss: 71065649152.0000 - val_mae: 23640.5137\n",
            "Epoch 44/100\n",
            "295/295 - 1s - 5ms/step - loss: 215746658304.0000 - mae: 28761.6094 - val_loss: 839050048.0000 - val_mae: 17096.0078\n",
            "Epoch 45/100\n",
            "295/295 - 1s - 3ms/step - loss: 74502234112.0000 - mae: 20196.6074 - val_loss: 637107712.0000 - val_mae: 16810.5273\n",
            "Epoch 46/100\n",
            "295/295 - 1s - 2ms/step - loss: 74119880704.0000 - mae: 19838.2930 - val_loss: 628755840.0000 - val_mae: 16773.9785\n",
            "Epoch 47/100\n",
            "295/295 - 1s - 2ms/step - loss: 74097418240.0000 - mae: 19779.9688 - val_loss: 623662272.0000 - val_mae: 16737.3633\n",
            "Epoch 48/100\n",
            "295/295 - 1s - 2ms/step - loss: 74067058688.0000 - mae: 19647.7363 - val_loss: 621805824.0000 - val_mae: 16704.3945\n",
            "Epoch 49/100\n",
            "295/295 - 1s - 2ms/step - loss: 74186473472.0000 - mae: 19854.1543 - val_loss: 645470208.0000 - val_mae: 16790.7812\n",
            "Epoch 50/100\n",
            "295/295 - 0s - 2ms/step - loss: 213205729280.0000 - mae: 29365.5977 - val_loss: 150422929408.0000 - val_mae: 26794.0410\n",
            "Epoch 51/100\n",
            "295/295 - 1s - 2ms/step - loss: 258491858944.0000 - mae: 29179.6504 - val_loss: 628936832.0000 - val_mae: 16748.1152\n",
            "Epoch 52/100\n",
            "295/295 - 1s - 2ms/step - loss: 74071875584.0000 - mae: 19654.8086 - val_loss: 621763072.0000 - val_mae: 16704.7500\n",
            "Epoch 53/100\n",
            "295/295 - 1s - 2ms/step - loss: 74065190912.0000 - mae: 19621.0430 - val_loss: 621889920.0000 - val_mae: 16706.8184\n",
            "Epoch 54/100\n",
            "295/295 - 0s - 2ms/step - loss: 74066485248.0000 - mae: 19637.3867 - val_loss: 622271488.0000 - val_mae: 16711.2402\n",
            "Epoch 55/100\n",
            "295/295 - 1s - 2ms/step - loss: 74070032384.0000 - mae: 19662.4570 - val_loss: 622401024.0000 - val_mae: 16710.9668\n",
            "Epoch 56/100\n",
            "295/295 - 1s - 2ms/step - loss: 74068353024.0000 - mae: 19645.5957 - val_loss: 621103168.0000 - val_mae: 16685.9453\n",
            "Epoch 57/100\n",
            "295/295 - 1s - 2ms/step - loss: 74099941376.0000 - mae: 19724.4980 - val_loss: 622697408.0000 - val_mae: 16702.8008\n",
            "Epoch 58/100\n",
            "295/295 - 1s - 2ms/step - loss: 123500036096.0000 - mae: 24738.6191 - val_loss: 4323554304.0000 - val_mae: 18255.2773\n",
            "Epoch 59/100\n",
            "295/295 - 1s - 2ms/step - loss: 122691067904.0000 - mae: 24636.8789 - val_loss: 1117012352.0000 - val_mae: 17113.2910\n",
            "Epoch 60/100\n",
            "295/295 - 1s - 2ms/step - loss: 75625947136.0000 - mae: 20663.8477 - val_loss: 633076736.0000 - val_mae: 16758.9629\n",
            "Epoch 61/100\n",
            "295/295 - 0s - 2ms/step - loss: 96680280064.0000 - mae: 23396.4316 - val_loss: 893176512.0000 - val_mae: 17092.6777\n",
            "Epoch 62/100\n",
            "295/295 - 1s - 3ms/step - loss: 161374961664.0000 - mae: 26842.0625 - val_loss: 7277875712.0000 - val_mae: 18316.0254\n",
            "Epoch 63/100\n",
            "295/295 - 1s - 4ms/step - loss: 102455418880.0000 - mae: 23708.7578 - val_loss: 2449164032.0000 - val_mae: 17519.9902\n",
            "Epoch 64/100\n",
            "295/295 - 1s - 3ms/step - loss: 82153144320.0000 - mae: 21633.4551 - val_loss: 711613504.0000 - val_mae: 16847.5234\n",
            "Epoch 65/100\n",
            "295/295 - 1s - 2ms/step - loss: 74378854400.0000 - mae: 20053.8848 - val_loss: 621950656.0000 - val_mae: 16690.6133\n",
            "Epoch 66/100\n",
            "295/295 - 0s - 2ms/step - loss: 86791733248.0000 - mae: 22307.8730 - val_loss: 780758144.0000 - val_mae: 16903.4141\n",
            "Epoch 67/100\n",
            "295/295 - 1s - 2ms/step - loss: 204159074304.0000 - mae: 28325.7188 - val_loss: 9330712576.0000 - val_mae: 18549.5410\n",
            "Epoch 68/100\n",
            "295/295 - 1s - 2ms/step - loss: 100234461184.0000 - mae: 23461.9766 - val_loss: 1820720896.0000 - val_mae: 17346.5195\n",
            "Epoch 69/100\n",
            "295/295 - 1s - 2ms/step - loss: 78837415936.0000 - mae: 21247.6660 - val_loss: 913757504.0000 - val_mae: 16990.0488\n",
            "Epoch 70/100\n",
            "295/295 - 1s - 2ms/step - loss: 75409989632.0000 - mae: 20354.2051 - val_loss: 624893824.0000 - val_mae: 16692.3926\n",
            "Epoch 71/100\n",
            "295/295 - 1s - 2ms/step - loss: 74087555072.0000 - mae: 19681.2129 - val_loss: 619749376.0000 - val_mae: 16649.1523\n",
            "Epoch 72/100\n",
            "295/295 - 1s - 2ms/step - loss: 78668496896.0000 - mae: 21125.5234 - val_loss: 1329758976.0000 - val_mae: 17172.5273\n",
            "Epoch 73/100\n",
            "295/295 - 1s - 2ms/step - loss: 208084434944.0000 - mae: 28323.1309 - val_loss: 8500946432.0000 - val_mae: 18445.0762\n",
            "Epoch 74/100\n",
            "295/295 - 0s - 2ms/step - loss: 96381313024.0000 - mae: 23117.3242 - val_loss: 1508860288.0000 - val_mae: 17237.5254\n",
            "Epoch 75/100\n",
            "295/295 - 1s - 2ms/step - loss: 77491552256.0000 - mae: 20976.4590 - val_loss: 829691904.0000 - val_mae: 16925.3047\n",
            "Epoch 76/100\n",
            "295/295 - 0s - 2ms/step - loss: 75034836992.0000 - mae: 20228.8730 - val_loss: 624429760.0000 - val_mae: 16680.5176\n",
            "Epoch 77/100\n",
            "295/295 - 1s - 2ms/step - loss: 74089693184.0000 - mae: 19677.9844 - val_loss: 619349120.0000 - val_mae: 16638.9395\n",
            "Epoch 78/100\n",
            "295/295 - 1s - 2ms/step - loss: 77882802176.0000 - mae: 20981.2520 - val_loss: 1176210560.0000 - val_mae: 17099.8711\n",
            "Epoch 79/100\n",
            "295/295 - 0s - 2ms/step - loss: 191578652672.0000 - mae: 27842.4062 - val_loss: 9101065216.0000 - val_mae: 18504.2539\n",
            "Epoch 80/100\n",
            "295/295 - 0s - 2ms/step - loss: 98590629888.0000 - mae: 23269.9727 - val_loss: 1573842176.0000 - val_mae: 17249.5488\n",
            "Epoch 81/100\n",
            "295/295 - 1s - 2ms/step - loss: 77668114432.0000 - mae: 21004.7988 - val_loss: 842753088.0000 - val_mae: 16924.6250\n",
            "Epoch 82/100\n",
            "295/295 - 1s - 5ms/step - loss: 75101323264.0000 - mae: 20256.1855 - val_loss: 627737792.0000 - val_mae: 16684.0371\n",
            "Epoch 83/100\n",
            "295/295 - 1s - 3ms/step - loss: 74105847808.0000 - mae: 19709.0137 - val_loss: 619132864.0000 - val_mae: 16634.5234\n",
            "Epoch 84/100\n",
            "295/295 - 1s - 2ms/step - loss: 77602471936.0000 - mae: 20933.5020 - val_loss: 1031295424.0000 - val_mae: 17024.0039\n",
            "Epoch 85/100\n",
            "295/295 - 1s - 2ms/step - loss: 175387607040.0000 - mae: 27280.5117 - val_loss: 8858530816.0000 - val_mae: 18469.1504\n",
            "Epoch 86/100\n",
            "295/295 - 1s - 2ms/step - loss: 98402902016.0000 - mae: 23242.9844 - val_loss: 1568072064.0000 - val_mae: 17239.8184\n",
            "Epoch 87/100\n",
            "295/295 - 0s - 2ms/step - loss: 77615775744.0000 - mae: 20985.9336 - val_loss: 839533248.0000 - val_mae: 16914.6523\n",
            "Epoch 88/100\n",
            "295/295 - 1s - 2ms/step - loss: 75089412096.0000 - mae: 20249.8418 - val_loss: 629193984.0000 - val_mae: 16681.3223\n",
            "Epoch 89/100\n",
            "295/295 - 1s - 2ms/step - loss: 74113982464.0000 - mae: 19718.7500 - val_loss: 618950464.0000 - val_mae: 16629.3965\n",
            "Epoch 90/100\n",
            "295/295 - 1s - 2ms/step - loss: 77229850624.0000 - mae: 20857.6543 - val_loss: 948504384.0000 - val_mae: 16973.1680\n",
            "Epoch 91/100\n",
            "295/295 - 1s - 2ms/step - loss: 161747009536.0000 - mae: 26734.3926 - val_loss: 8077730816.0000 - val_mae: 18372.0938\n",
            "Epoch 92/100\n",
            "295/295 - 0s - 2ms/step - loss: 96315408384.0000 - mae: 23066.2344 - val_loss: 1476687872.0000 - val_mae: 17203.0117\n",
            "Epoch 93/100\n",
            "295/295 - 1s - 2ms/step - loss: 77256327168.0000 - mae: 20902.4043 - val_loss: 815758784.0000 - val_mae: 16892.1113\n",
            "Epoch 94/100\n",
            "295/295 - 1s - 2ms/step - loss: 74981113856.0000 - mae: 20205.8711 - val_loss: 628534592.0000 - val_mae: 16673.8809\n",
            "Epoch 95/100\n",
            "295/295 - 1s - 2ms/step - loss: 74113032192.0000 - mae: 19711.4336 - val_loss: 618756992.0000 - val_mae: 16624.1211\n",
            "Epoch 96/100\n",
            "295/295 - 1s - 2ms/step - loss: 76818604032.0000 - mae: 20764.8926 - val_loss: 895771456.0000 - val_mae: 16937.0645\n",
            "Epoch 97/100\n",
            "295/295 - 1s - 2ms/step - loss: 149580546048.0000 - mae: 26191.4512 - val_loss: 7064819712.0000 - val_mae: 18242.4688\n",
            "Epoch 98/100\n",
            "295/295 - 0s - 2ms/step - loss: 93334298624.0000 - mae: 22803.8984 - val_loss: 1338622208.0000 - val_mae: 17149.0918\n",
            "Epoch 99/100\n",
            "295/295 - 1s - 2ms/step - loss: 76730826752.0000 - mae: 20776.6758 - val_loss: 780982144.0000 - val_mae: 16862.0684\n",
            "Epoch 100/100\n",
            "295/295 - 1s - 2ms/step - loss: 74821156864.0000 - mae: 20138.0000 - val_loss: 626590400.0000 - val_mae: 16664.1211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test mae: %.3f' % mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXkbWexQrrdL",
        "outputId": "6516823b-9392-4b9d-e236-034ca5bb9931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test mae: 17556.889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBqLtvisrue5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}